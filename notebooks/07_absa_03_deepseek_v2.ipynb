{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, PromptTuningConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\finam_hotel_reviews\\notebooks\n"
     ]
    }
   ],
   "source": [
    "def find_project_root() -> Path:\n",
    "\n",
    "    start_path = Path.cwd()\n",
    "    for parent in start_path.parents:\n",
    "        if (parent / \".git\").exists() or (parent / \"pyproject.toml\").exists() or (parent / \"setup.py\").exists():\n",
    "            return parent\n",
    "    return start_path  # Fallback: if no marker is found, return the original path\n",
    "\n",
    "\n",
    "# Get the project root automatically\n",
    "PROJECT_ROOT = find_project_root()\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s - %(name)s -%(levelname)s - %(funcName)s -  %(message)s\",\n",
    "#     handlers=[logging.StreamHandler(), logging.FileHandler(PROJECT_ROOT / \"logs\" / \"logfile.log\")],\n",
    "# )\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd64e72001a14abf9d52a70796a99e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 71,680 || all params: 7,615,688,192 || trainable%: 0.0009\n",
      "None\n",
      " DeepSeek LLM загружен с Prompt Tuning и 4-битным квантованием!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"lightblue/DeepSeek-R1-Distill-Qwen-7B-Multilingual\"\n",
    "\n",
    "# Настройка 4-битной квантования\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16  # Use float16 for faster computation\n",
    ")\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "# Настройка Prompt Tuning\n",
    "prompt_tuning_config = PromptTuningConfig(\n",
    "    task_type=\"CAUSAL_LM\", num_virtual_tokens=20  # Тип задачи  # Количество виртуальных токенов для оптимизации\n",
    ")\n",
    "\n",
    "# Применение Prompt Tuning\n",
    "model = get_peft_model(model, prompt_tuning_config)\n",
    "# logging.info(model.print_trainable_parameters())\n",
    "print(model.print_trainable_parameters())\n",
    "\n",
    "# logging.info(\" DeepSeek LLM загружен с Prompt Tuning и 4-битным квантованием!\")\n",
    "print(\" DeepSeek LLM загружен с Prompt Tuning и 4-битным квантованием!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "system_prompt = \"Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.:\"\n",
    "df_initial = pd.read_csv(PROJECT_ROOT / \"data\" / \"interim\" / \"200_labeled_gpt_4.csv\")\n",
    "df_initial.head(2)\n",
    "\n",
    "ls_labels_raw = df_initial[\"labels\"].to_list()\n",
    "\n",
    "ls_aspect = []\n",
    "ls_sentiment = []\n",
    "ls_text = df_initial[\"text\"].to_list()\n",
    "ls_labels = []\n",
    "ls_big_text = []\n",
    "\n",
    "for label in ls_labels_raw:\n",
    "    label_json = json.loads(label.replace(\"'\", '\"'))\n",
    "    ls_labels.append(label_json)\n",
    "\n",
    "for text, label in zip(ls_text, ls_labels_raw):\n",
    "    fin_text = system_prompt + f\"``` {text} ```  ответ: ``` {label} ```\"\n",
    "    ls_big_text.append(fin_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "data = {\"text\": ls_text, \"labels_raw\": ls_labels_raw, \"labels_json\": ls_labels, \"text_prompt_label\": ls_big_text}\n",
    "\n",
    "# Создаем Dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Разделяем на train/test\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "# Создаем DatasetDict\n",
    "# dataset_dict = DatasetDict(\n",
    "#     {\"train\": dataset[\"train\"], \"test\": dataset[\"test\"], \"text_prompt_label\": dataset[\"text_prompt_label\"]}\n",
    "# )\n",
    "\n",
    "# # Проверяем структуру\n",
    "# print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels_raw', 'labels_json', 'text_prompt_label'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels_raw', 'labels_json', 'text_prompt_label'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce9c9a850f749059a8d68722d4563a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eb0cc806d6469c92b255387e79c4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sample with Labels:\n",
      "{'text': 'Невероятный отель с лучшими номерами. Чего стоят только эти матрасы, на которые ложишься и не можешь встать. В самом центре города. Шоппинг, достопримечательности - все рядом. Завтраки наивкуснейшие! Очень советую любителям шикарно отдохнуть!', 'labels_raw': \"[{'aspect': 'общее впечатление', 'sentiment': 'positive'}, {'aspect': 'номер', 'sentiment': 'positive'}, {'aspect': 'матрасы', 'sentiment': 'positive'}, {'aspect': 'расположение', 'sentiment': 'positive'}, {'aspect': 'достопримечательности', 'sentiment': 'positive'}, {'aspect': 'завтрак', 'sentiment': 'positive'}]\", 'labels_json': [{'aspect': 'общее впечатление', 'sentiment': 'positive'}, {'aspect': 'номер', 'sentiment': 'positive'}, {'aspect': 'матрасы', 'sentiment': 'positive'}, {'aspect': 'расположение', 'sentiment': 'positive'}, {'aspect': 'достопримечательности', 'sentiment': 'positive'}, {'aspect': 'завтрак', 'sentiment': 'positive'}], 'text_prompt_label': \"Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.:``` Невероятный отель с лучшими номерами. Чего стоят только эти матрасы, на которые ложишься и не можешь встать. В самом центре города. Шоппинг, достопримечательности - все рядом. Завтраки наивкуснейшие! Очень советую любителям шикарно отдохнуть! ```  ответ: ``` [{'aspect': 'общее впечатление', 'sentiment': 'positive'}, {'aspect': 'номер', 'sentiment': 'positive'}, {'aspect': 'матрасы', 'sentiment': 'positive'}, {'aspect': 'расположение', 'sentiment': 'positive'}, {'aspect': 'достопримечательности', 'sentiment': 'positive'}, {'aspect': 'завтрак', 'sentiment': 'positive'}] ```\", 'input_ids': [151646, 20195, 32642, 7599, 60290, 1792, 33513, 20264, 25428, 5409, 126891, 12150, 125796, 73934, 49707, 13, 124713, 46195, 18362, 60290, 1792, 73626, 126979, 95473, 125286, 4552, 11, 13073, 128548, 25460, 21259, 139592, 20562, 7587, 18658, 44483, 131260, 5805, 6597, 17998, 13, 22933, 136147, 38133, 18673, 126225, 131644, 13, 128936, 28156, 8005, 126604, 11, 66325, 28156, 2184, 16104, 55757, 59890, 67642, 481, 43993, 140284, 13, 52577, 17753, 1792, 124956, 1802, 13073, 26991, 126099, 126362, 127403, 0, 140153, 131847, 33048, 125389, 130340, 6442, 54517, 74181, 2184, 13685, 20264, 128749, 10474, 130665, 0, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [151646, 20195, 32642, 7599, 60290, 1792, 33513, 20264, 25428, 5409, 126891, 12150, 125796, 73934, 49707, 13, 124713, 46195, 18362, 60290, 1792, 73626, 126979, 95473, 125286, 4552, 11, 13073, 128548, 25460, 21259, 139592, 20562, 7587, 18658, 44483, 131260, 5805, 6597, 17998, 13, 22933, 136147, 38133, 18673, 126225, 131644, 13, 128936, 28156, 8005, 126604, 11, 66325, 28156, 2184, 16104, 55757, 59890, 67642, 481, 43993, 140284, 13, 52577, 17753, 1792, 124956, 1802, 13073, 26991, 126099, 126362, 127403, 0, 140153, 131847, 33048, 125389, 130340, 6442, 54517, 74181, 2184, 13685, 20264, 128749, 10474, 130665, 0, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]}\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # Use input_ids as labels for causal LM\n",
    "    return inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Verify tokenized sample\n",
    "print(\"Tokenized Sample with Labels:\")\n",
    "print(tokenized_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Disabled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baksa\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CLEARML_DISABLED\"] = \"true\"\n",
    "os.environ[\"DVCLIVE_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=PROJECT_ROOT / \"results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=PROJECT_ROOT / \"logs\",\n",
    "    fp16=True,\n",
    "    report_to=[],  # Отключает интеграции (DVC, ClearML, WandB и т.д.)\n",
    ")\n",
    "\n",
    "# logging.info(\"WandB Disabled!\")\n",
    "print(\"WandB Disabled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize trainer and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer Initialized!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset.remove_columns([\"text\"]),  # Remove raw text column\n",
    "    eval_dataset=small_test_dataset.remove_columns([\"text\"]),\n",
    ")\n",
    "\n",
    "print(\"Trainer Initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared CUDA Cache\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(\"Cleared CUDA Cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune DeepSeek LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Fine-Tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 01:34, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.551310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.323419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.122530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.959853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=6.884547424316406, metrics={'train_runtime': 96.5585, 'train_samples_per_second': 5.178, 'train_steps_per_second': 0.621, 'total_flos': 1.0078517081407488e+16, 'train_loss': 6.884547424316406, 'epoch': 4.64})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"🚀 Starting Fine-Tuning...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Это был самый маленький по площади номер из всех отелей, где я останавливалась. Тем не менее, очень уютненький и комфортабельный мини отельчик. Мебель новая, все функционирует, удобно расположен. Учитывая дороговизну отелей Парижа, для эконом варианта вполне достойно.Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baksa\\AppData\\Roaming\\Python\\Python311\\site-packages\\peft\\peft_model.py:1889: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n",
      "  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Это был самый маленький по площади номер из всех отелей, где я останавливалась. Тем не менее, очень уютненький и комфортабельный мини отельчик. Мебель новая, все функционирует, удобно расположен. Учитывая дороговизну отелей Парижа, для эконом варианта вполне достойно.Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic_weight\", \"toxic_type\": \"toxic_type\"}: json: {\"name\": \"Отель number\", \"address\": \"number\", \"rating\": \"number\", \"description\": \"text\", \"category\": \"text\", \"toxic\": \"toxic\", \"toxic_weight\": \"toxic\n",
      "--------------------------------------------------------------------------------\n",
      "Review: Понравилось всё!!! От персонала до оснащения номера!!! Модно,стильно,уютно. Огромный плазменный телевизор в номере, наличие банных принадлежностей (для мини-отеля это редкость), любезно предоставленная посуда,которая понадобилась в ходе проживания, ванная комната с просто блестящей сантехникой - всё это сложило невероятно приятное впечатление о гостинице!!! Девушка на ресепшене встретила с улыбкой, всё подробно объяснила, посоветовала. Желаю отелю дальнейшего процветания!Огромное спасибо за возможность прекрасно провести время!Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.:\n",
      "Predicted Sentiment: Понравилось всё!!! От персонала до оснащения номера!!! Модно,стильно,уютно. Огромный плазменный телевизор в номере, наличие банных принадлежностей (для мини-отеля это редкость), любезно предоставленная посуда,которая понадобилась в ходе проживания, ванная комната с просто блестящей сантехникой - всё это сложило невероятно приятное впечатление о гостинице!!! Девушка на ресепшене встретила с улыбкой, всё подробно объяснила, посоветовала. Желаю отелю дальнейшего процветания!Огромное спасибо за возможность прекрасно провести время!Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Статус: \"ok\". Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\": [\"...\"], \"tone\": [\"...\"], \"comments\": [\"...\"]}, \"total\": [\"...\"]}. Пример: {\"ana\":\n",
      "--------------------------------------------------------------------------------\n",
      "Review: В сердце парижа, в 5 минутах ходьбы от Нотр-Дам, если есть желание пешком исследовать весь Париж, идеальное расположение.Отличные завтраки подают с 7 утра, правда, за дополнительные деньги. Всего шесть этажей, есть маленький лифт, с верхних этажей открываются прекрасные виды на Сену, собор и Сан мишель.Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.:\n",
      "Predicted Sentiment: В сердце парижа, в 5 минутах ходьбы от Нотр-Дам, если есть желание пешком исследовать весь Париж, идеальное расположение.Отличные завтраки подают с 7 утра, правда, за дополнительные деньги. Всего шесть этажей, есть маленький лифт, с верхних этажей открываются прекрасные виды на Сену, собор и Сан мишель.Ты - аналитие по анализу отзывов. Разметь данный отзыв об отеле, выделяя все возможные аспекты и их тональность. Ответ в формате json.: { \"negative\": [\"отель\"], \"positive\": [\"отель\"] }, \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"отель\"], \"positive\": [\"отель\"], \"neutral\": [\"отель\"] }, \"negative\": [\"от\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generate_prediction(review_text):\n",
    "    inputs = tokenizer(review_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Example reviews\n",
    "reviews = [ls_text[0], ls_text[1], ls_text[2]]\n",
    "reviews = [ls_text[0] + system_prompt, ls_text[1] + system_prompt, ls_text[2] + system_prompt]\n",
    "\n",
    "# Run predictions\n",
    "for review in reviews:\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Sentiment: {generate_prediction(review)}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
