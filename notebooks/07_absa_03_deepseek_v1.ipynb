{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, PromptTuningConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\finam_hotel_reviews\\notebooks\n"
     ]
    }
   ],
   "source": [
    "def find_project_root() -> Path:\n",
    "\n",
    "    start_path = Path.cwd()\n",
    "    for parent in start_path.parents:\n",
    "        if (parent / \".git\").exists() or (parent / \"pyproject.toml\").exists() or (parent / \"setup.py\").exists():\n",
    "            return parent\n",
    "    return start_path  # Fallback: if no marker is found, return the original path\n",
    "\n",
    "\n",
    "# Get the project root automatically\n",
    "PROJECT_ROOT = find_project_root()\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s - %(name)s -%(levelname)s - %(funcName)s -  %(message)s\",\n",
    "#     handlers=[logging.StreamHandler(), logging.FileHandler(PROJECT_ROOT / \"logs\" / \"logfile.log\")],\n",
    "# )\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d3dcdb99024f33a97b2165c2f4e7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 71,680 || all params: 7,615,688,192 || trainable%: 0.0009\n",
      "None\n",
      " DeepSeek LLM загружен с Prompt Tuning и 4-битным квантованием!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"lightblue/DeepSeek-R1-Distill-Qwen-7B-Multilingual\"\n",
    "\n",
    "# Настройка 4-битной квантования\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16  # Use float16 for faster computation\n",
    ")\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "# Настройка Prompt Tuning\n",
    "prompt_tuning_config = PromptTuningConfig(\n",
    "    task_type=\"CAUSAL_LM\", num_virtual_tokens=20  # Тип задачи  # Количество виртуальных токенов для оптимизации\n",
    ")\n",
    "\n",
    "# Применение Prompt Tuning\n",
    "model = get_peft_model(model, prompt_tuning_config)\n",
    "# logging.info(model.print_trainable_parameters())\n",
    "print(model.print_trainable_parameters())\n",
    "\n",
    "# logging.info(\" DeepSeek LLM загружен с Prompt Tuning и 4-битным квантованием!\")\n",
    "print(\" DeepSeek LLM загружен с Prompt Tuning и 4-битным квантованием!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df_initial = pd.read_csv(PROJECT_ROOT / \"data\" / \"interim\" / \"200_labeled_gpt_4.csv\")\n",
    "df_initial.head(2)\n",
    "\n",
    "ls_labels_raw = df_initial[\"labels\"].to_list()\n",
    "\n",
    "ls_aspect = []\n",
    "ls_sentiment = []\n",
    "ls_text = df_initial[\"text\"].to_list()\n",
    "ls_labels = []\n",
    "\n",
    "for label in ls_labels_raw:\n",
    "    label_json = json.loads(label.replace(\"'\", '\"'))\n",
    "    ls_labels.append(label_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels_raw', 'labels_json'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels_raw', 'labels_json'],\n",
      "        num_rows: 40\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "data = {\"text\": ls_text, \"labels_raw\": ls_labels_raw, \"labels_json\": ls_labels}\n",
    "\n",
    "# Создаем Dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Разделяем на train/test\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "# Создаем DatasetDict\n",
    "dataset_dict = DatasetDict({\"train\": dataset[\"train\"], \"test\": dataset[\"test\"]})\n",
    "\n",
    "# Проверяем структуру\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74704b22221247e6896ee1637379fb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b15396e9bd4404197d04f5b98438752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sample with Labels:\n",
      "{'text': 'Невероятный отель с лучшими номерами. Чего стоят только эти матрасы, на которые ложишься и не можешь встать. В самом центре города. Шоппинг, достопримечательности - все рядом. Завтраки наивкуснейшие! Очень советую любителям шикарно отдохнуть!', 'labels_raw': \"[{'aspect': 'общее впечатление', 'sentiment': 'positive'}, {'aspect': 'номер', 'sentiment': 'positive'}, {'aspect': 'матрасы', 'sentiment': 'positive'}, {'aspect': 'расположение', 'sentiment': 'positive'}, {'aspect': 'достопримечательности', 'sentiment': 'positive'}, {'aspect': 'завтрак', 'sentiment': 'positive'}]\", 'labels_json': [{'aspect': 'общее впечатление', 'sentiment': 'positive'}, {'aspect': 'номер', 'sentiment': 'positive'}, {'aspect': 'матрасы', 'sentiment': 'positive'}, {'aspect': 'расположение', 'sentiment': 'positive'}, {'aspect': 'достопримечательности', 'sentiment': 'positive'}, {'aspect': 'завтрак', 'sentiment': 'positive'}], 'input_ids': [151646, 20195, 32642, 7599, 60290, 1792, 33513, 20264, 25428, 5409, 126891, 12150, 125796, 73934, 49707, 13, 124713, 46195, 18362, 60290, 1792, 73626, 126979, 95473, 125286, 4552, 11, 13073, 128548, 25460, 21259, 139592, 20562, 7587, 18658, 44483, 131260, 5805, 6597, 17998, 13, 22933, 136147, 38133, 18673, 126225, 131644, 13, 128936, 28156, 8005, 126604, 11, 66325, 28156, 2184, 16104, 55757, 59890, 67642, 481, 43993, 140284, 13, 52577, 17753, 1792, 124956, 1802, 13073, 26991, 126099, 126362, 127403, 0, 140153, 131847, 33048, 125389, 130340, 6442, 54517, 74181, 2184, 13685, 20264, 128749, 10474, 130665, 0, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [151646, 20195, 32642, 7599, 60290, 1792, 33513, 20264, 25428, 5409, 126891, 12150, 125796, 73934, 49707, 13, 124713, 46195, 18362, 60290, 1792, 73626, 126979, 95473, 125286, 4552, 11, 13073, 128548, 25460, 21259, 139592, 20562, 7587, 18658, 44483, 131260, 5805, 6597, 17998, 13, 22933, 136147, 38133, 18673, 126225, 131644, 13, 128936, 28156, 8005, 126604, 11, 66325, 28156, 2184, 16104, 55757, 59890, 67642, 481, 43993, 140284, 13, 52577, 17753, 1792, 124956, 1802, 13073, 26991, 126099, 126362, 127403, 0, 140153, 131847, 33048, 125389, 130340, 6442, 54517, 74181, 2184, 13685, 20264, 128749, 10474, 130665, 0, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]}\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # Use input_ids as labels for causal LM\n",
    "    return inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Verify tokenized sample\n",
    "print(\"Tokenized Sample with Labels:\")\n",
    "print(tokenized_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Disabled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baksa\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CLEARML_DISABLED\"] = \"true\"\n",
    "os.environ[\"DVCLIVE_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=PROJECT_ROOT / \"results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=PROJECT_ROOT / \"logs\",\n",
    "    fp16=True,\n",
    "    report_to=[],  # Отключает интеграции (DVC, ClearML, WandB и т.д.)\n",
    ")\n",
    "\n",
    "# logging.info(\"WandB Disabled!\")\n",
    "print(\"WandB Disabled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize trainer and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\baksa\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Trainer Initialized!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset.remove_columns([\"text\"]),  # Remove raw text column\n",
    "    eval_dataset=small_test_dataset.remove_columns([\"text\"]),\n",
    ")\n",
    "\n",
    "print(\"Trainer Initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared CUDA Cache\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(\"Cleared CUDA Cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune DeepSeek LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Fine-Tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.588213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=7.874982833862305, metrics={'train_runtime': 21.4747, 'train_samples_per_second': 4.657, 'train_steps_per_second': 0.559, 'total_flos': 2085210430636032.0, 'train_loss': 7.874982833862305, 'epoch': 0.96})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"🚀 Starting Fine-Tuning...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Это был самый маленький по площади номер из всех отелей, где я останавливалась. Тем не менее, очень уютненький и комфортабельный мини отельчик. Мебель новая, все функционирует, удобно расположен. Учитывая дороговизну отелей Парижа, для эконом варианта вполне достойно.\n",
      "Predicted Sentiment: Это был самый маленький по площади номер из всех отелей, где я останавливалась. Тем не менее, очень уютненький и комфортабельный мини отельчик. Мебель новая, все функционирует, удобно расположен. Учитывая дороговизну отелей Парижа, для эконом варианта вполне достойно. Странно, но мне кажется, что я где-то уже был. Или, возможно, я где-то уже был. В любом случае, это был очень комфортабельный номер, и я постараюсь найти этот номер в следующем разе.\"\"\"\n",
      "\n",
      "<think>\n",
      "Хорошо, мне нужно понять, что такое \"mini-chic\" отелей и почему они особенно популярны в Париже. Я слышал, что mini-chic отелей — это небольшие отелей с современными мебелью и функциональными концертами. Но как именно это получается? Может быть, они где-то隐蔽но или specially-contrived?\n",
      "\n",
      "Но в конкретном контексте, я вижу, что пользователь описывает свой опыт с mini-chic отелем в Париже. Он говорит о том, что был там, где он останавливался, и что это был самый маленький по площади номер, но очень удобный и комфортабельный. Также упоминается, что мебель новая и все функционирует, удобно расположен. Дороговизна отелей Парижа, для эконом варианта вполне достойно. Странно, но мне кажется, что я где-то уже был. Или, возможно, я где-то уже был. В любом случае, это был очень комфортабельный номер, и он постараюсь найти этот номер в следующем разе.\n",
      "\n",
      "Поскольку пользователь не просит конкретного ответа, а просит объяснить, что это mini-chic отелей и почему они особенно популярны, я должен предоставить подробное объяснение.\n",
      "\n",
      "Начну с того, что mini-chic отелей — это небольшие отелей с современными мебелью и функциональными концертами. Они обычно隐蔽ны или specially-contrived, чтобы быть недоступными для прямого посещения. Это делает их особенно популярными, потому что они находятся в скрытом виде, что создает ощущение тajмака и уникальности.\n",
      "\n",
      "Мне кажется, что mini-chic отелей популярны в Париже, потому что Париж — это город с большим количеством вил, и их размещение в скрытом виде позволяет создать уникальный и элегантный вибр. Также, что важно, это удобно для посещителей, которые хотят сохранить часть своей сутки в приватности или для тех, кто ищет непосмотримое место.\n",
      "\n",
      "Кроме того, mini-chic отелей часто имеют современные функции, такие как концерты, батареи, или другие современные мечты, что делает их особенно привлекательными для гостей.\n",
      "\n",
      "Также стоит упомянуть, что mini-chic отелей часто находятся в скрытом виде, что создает ощущение тajмака и уникальности, что делает их особенно популярными среди гостей.\n",
      "\n",
      "В итоге, mini-chic отелей — это уникальный и современный отель с функциональными концертами и современными мебелью, которые делают их особенно популярными в Париже и других городах, где есть большой количество вил.\n",
      "</think>\n",
      "\n",
      " mini-chic отелей — это небольшие отелей с современными мебелью и функциональными концертами, находящиеся в скрытом виде. Они популярны в Париже, потому что их размещение в скрытом виде создает уникальный и элегантный вибр, а современные функции делают их привлекательными для гостей. mini-chic отелей часто находятся в скрытом виде, что делает их особенно популярными среди гостей. Также они часто имеют современные функции, такие как концерты, батареи или другие современные мечты.\n",
      "--------------------------------------------------------------------------------\n",
      "Review: Понравилось всё!!! От персонала до оснащения номера!!! Модно,стильно,уютно. Огромный плазменный телевизор в номере, наличие банных принадлежностей (для мини-отеля это редкость), любезно предоставленная посуда,которая понадобилась в ходе проживания, ванная комната с просто блестящей сантехникой - всё это сложило невероятно приятное впечатление о гостинице!!! Девушка на ресепшене встретила с улыбкой, всё подробно объяснила, посоветовала. Желаю отелю дальнейшего процветания!Огромное спасибо за возможность прекрасно провести время!\n",
      "Predicted Sentiment: Понравилось всё!!! От персонала до оснащения номера!!! Модно,стильно,уютно. Огромный плазменный телевизор в номере, наличие банных принадлежностей (для мини-отеля это редкость), любезно предоставленная посуда,которая понадобилась в ходе проживания, ванная комната с просто блестящей сантехникой - всё это сложило невероятно приятное впечатление о гостинице!!! Девушка на ресепшене встретила с улыбкой, всё подробно объяснила, посоветовала. Желаю отелю дальнейшего процветания!Огромное спасибо за возможность прекрасно провести время! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спасибо! Спас\n",
      "--------------------------------------------------------------------------------\n",
      "Review: В сердце парижа, в 5 минутах ходьбы от Нотр-Дам, если есть желание пешком исследовать весь Париж, идеальное расположение.Отличные завтраки подают с 7 утра, правда, за дополнительные деньги. Всего шесть этажей, есть маленький лифт, с верхних этажей открываются прекрасные виды на Сену, собор и Сан мишель.\n",
      "Predicted Sentiment: В сердце парижа, в 5 минутах ходьбы от Нотр-Дам, если есть желание пешком исследовать весь Париж, идеальное расположение.Отличные завтраки подают с 7 утра, правда, за дополнительные деньги. Всего шесть этажей, есть маленький лифт, с верхних этажей открываются прекрасные виды на Сену, собор и Сан мишель. Надо быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижу, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не вижать, как это может помочь. Нужно быть готовым к любому, если есть какие-то проблемы, можно пешком пройти по лестнице. В российских домах есть 1-2 комнаты, как и в других. Дорожки между домами, как и в других, имеют разные цвета, и я, как новичок, не\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generate_prediction(review_text):\n",
    "    inputs = tokenizer(review_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Example reviews\n",
    "reviews = [ls_text[0], ls_text[1], ls_text[2]]\n",
    "\n",
    "# Run predictions\n",
    "for review in reviews:\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Sentiment: {generate_prediction(review)}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Понравилось всё!!! От персонала до оснащения номера!!! Модно,стильно,уютно. Огромный плазменный телевизор в номере, наличие банных принадлежностей (для мини-отеля это редкость), любезно предоставленная посуда,которая понадобилась в ходе проживания, ванная комната с просто блестящей сантехникой - всё это сложило невероятно приятное впечатление о гостинице!!! Девушка на ресепшене встретила с улыбкой, всё подробно объяснила, посоветовала. Желаю отелю дальнейшего процветания!Огромное спасибо за возможность прекрасно провести время!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_text[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
